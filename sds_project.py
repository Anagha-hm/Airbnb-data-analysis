# -*- coding: utf-8 -*-
"""SDS Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DxvqQ1UJHuWStiZcF_9FjtIcTarnwBKj
"""

import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from scipy import stats

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
uploaded=files.upload()

data = pd.read_csv("AirbnbData.csv")
data.head() # DISPLAYS FIRST 5 DATA COLOUMNS

"""DATA CLEANING

"""

data.shape

#DataSet Description 
# Consists of 16 columns 
#ID - A unique code given to each user 
#HOST_ID - An ID provided to each AirBnb location
#LATITUDE - Latitude of the AirBnb Location
#LONGITUDE - Longitude of the AirBnb Location
#PRICE - Cost per night in the room
#MINIMUM_NIGHTS - Miniumum duration of stay
#NUMBER_OF_REVIEWS - Reviews available for a particular location
#LAST_REVIEW - Date of the last review of the AirBnb
#REVIEWS_PER_MONTH - Number of user reviews per month
#CLACULATED_HOST_LISTING_COUNT - Number of total customers who have stayed in a particular AirBnb
#AVAILABLITY_365 - Number of days available in the year
#NAME- Name of the AirBnb
#HOST_NAME- The owner of the AirBnb
#NEIGHBOURHOOD_GROUP - The region the AirBnb is located 
#NEIGHBOURHOOD - Name of the locality of the AirBnb
#ROOM_TYPE - Type of room ( private / shared / whole apartment or house )

data.shape # Gives the dimensions of the data set
data.info()  # Gives the information of the type of data in each coloumn

#FIND NUMBER OF NULL VALUES IN EACH COLOUMN 
data.isnull().sum()
#AS SEEN FROM THE TABLE BELOW , LAST_REVIEW AND REVIEWS PER MONTH HAVE A LOT OF MISSING VALUES AND THE COLOUMNS CAN THUS BE DROPPED

drop=["last_review","reviews_per_month"]
data.drop(drop, inplace=True, axis=1)
data.shape
#IT CAN BE SEEN THAT NUMBER OF COLOUMNS REDUCES BY 2 
#NOW THERE ARE 14 USABLE COLOUMNS IN THE DATA SET

data.columns
data.nunique()
#NUMBER OF COLOUMNS WITH NUMBER OF UNIQUE ROWS

data.fillna("NULL", inplace=True)
#FILL THE EMPTY NAME COLOUMN WITH MODE VALUE TO AVOID ERRORS
data.isnull().sum()
#NOW THERE ARE NO ROWS WITH EMPTY VALUES

#CAPITALISATION FOR ALL CATEGORICAL DATA
data['name'] = data['name'].str.upper()
data['host_name'] = data['host_name'].str.upper()
data['neighbourhood_group'] = data['neighbourhood_group'].str.upper()
data['neighbourhood'] = data['neighbourhood'].str.upper()
data.head()

#DETECTION AND REMOVAL OF OUTLIERS 

Q1 = data.price.quantile(0.25)
Q3 = data.price.quantile(0.75)
IQR = Q3 - Q1
upper_limit=Q3+1.5*IQR
lower_limit=Q1-1.5*IQR

data_filtered=data[(data['price']>lower_limit) & (data['price']<upper_limit)]
data_filtered.shape
print(data_filtered.shape)

Q1 = data_filtered.minimum_nights.quantile(0.25)
Q3 = data_filtered.minimum_nights.quantile(0.75)
IQR = Q3 - Q1
upper_limit=Q3+1.5*IQR
lower_limit=Q1-1.5*IQR

data_filtered=data[(data['minimum_nights']>lower_limit) & (data['minimum_nights']<upper_limit)]
data_filtered.shape
print(data_filtered.shape)

"""EXPLORATORY DATA ANALYSIS"""

#GRAPH VISUALISATION 

fig = plt.figure(figsize = (10,15))
ax = fig.gca()
data_filtered.hist(ax=ax)
plt.show()

plt.figure(figsize=(10,40))
sns.catplot(x='neighbourhood_group',kind="count",palette='BuPu',data=data_filtered)

plt.figure(figsize=(10,15))
sns.catplot(x='room_type',kind="count",palette='BuPu',data=data_filtered)

plt.figure(figsize=(10,6))
sns.scatterplot(data_filtered.longitude,data_filtered.latitude,hue=data_filtered.neighbourhood_group,palette='BuPu')

#NEIGHBOURHOOD GROUP VS PRICE - BARCHART

plt.figure(figsize=(15,6))
result = data_filtered.groupby(["neighbourhood_group"])['price'].aggregate(np.median).reset_index().sort_values('price')
sns.barplot(x='neighbourhood_group', y="price", data=data_filtered, order=result['neighbourhood_group'],palette='BuPu') 
plt.show()

#ROOM TYPE VS PRICE - BARCHART

plt.figure(figsize=(15,6))
result = data_filtered.groupby(["room_type"])['price'].aggregate(np.median).reset_index().sort_values('price')
sns.barplot(x='room_type', y="price", data=data_filtered, order=result['room_type'],palette='BuPu') 
plt.show()

#neighbourhood_group VS minimum_nights -BARCHART
plt.figure(figsize=(15,6))
result = data_filtered.groupby(["neighbourhood_group"])['minimum_nights'].aggregate(np.median).reset_index().sort_values('minimum_nights')
sns.barplot(x='neighbourhood_group', y="minimum_nights", data=data_filtered, order=result['neighbourhood_group'],palette='BuPu') 
plt.show()

#neighbourhood_group - availability_365 BARCHART
plt.figure(figsize=(15,6))
result = data_filtered.groupby(["neighbourhood_group"])['availability_365'].aggregate(np.median).reset_index().sort_values('availability_365')
sns.barplot(x='neighbourhood_group', y="availability_365", data=data_filtered, order=result['neighbourhood_group'],palette='BuPu')
plt.show()

#ROOM TYPE VS LOCATION - SCATTERPLOT

plt.figure(figsize=(15,6))
sns.scatterplot(data_filtered.longitude,data_filtered.latitude,hue=data_filtered.room_type,palette='BuPu')

"""NORMALISATION """

#Find mean and variance of all coloumns 
print(data_filtered.mean())
print('\n\n')
print(data_filtered.var())

from sklearn.preprocessing import normalize
x=np.array([data_filtered['price'],data_filtered['minimum_nights']])
normalized_X = normalize(x)
print(normalized_X)
data_filtered= data_filtered.drop(['price','minimum_nights'],axis=1)
data_filtered.insert(4,'price',normalized_X[0])
data_filtered.insert(5,'minimum_nights',normalized_X[1])
data_filtered.head()

print(data_filtered.price.mean())
print(data_filtered.price.var())
print("\n")
print(data_filtered.minimum_nights.mean())
print(data_filtered.minimum_nights.var())

sns.kdeplot(data_filtered.price)

sns.kdeplot(data_filtered.minimum_nights)

"""**HYPOTHESIS TESTING**"""

from statsmodels.stats import weightstats as mstats

#H0=THE MEAN PRICE OF THE ROOMS IN THE EAST REGION AND WEST REGION IS EQUALTO THE POPULATION MEAN
#H1=THE MEAN PRICE OF THE ROOMS IN THE EAST REGION AND WEST REGION IS SMALLER THAN THE POPULATION MEAN

dt = pd.read_csv("AirbnbData.csv")
east = dt[dt['neighbourhood_group'] == 'East Region']
east=east[:50]#The first 50 rooms from the east region
fig = plt.figure()
res = stats.probplot(east['price'], plot=plt)
plt.show()
west=dt[dt['neighbourhood_group'] == 'West Region']
west=west[:50]#The first 50 rooms from west region
fig = plt.figure()
res = stats.probplot(west['price'], plot=plt)
plt.show()

#The zscore values for the east and west regions
print(stats.zscore(east['price']))
print(stats.zscore(west['price']))

#calculating the mean price of the population, eat region an  the west region
population_mean=data['price'].mean()
east_mean=east['price'].mean()
west_mean=west['price'].mean()
print(population_mean,east_mean)
print(population_mean,west_mean)
#pvalues
zstat, pvalue = mstats.ztest(east['price'],x2=None,value=population_mean,alternative='smaller')
print(float(pvalue))
zstat, pvalue = mstats.ztest(west['price'],x2=None,value=population_mean,alternative='smaller')
print(float(pvalue))

#The pvalue for the H0 hypothesis is 0.09.This indicates that the possibility of H0 being true is very small and thus it can be rejected.

"""CORRELATION BETWEEN COLUMNS """

plt.figure(figsize=(8,8))
sns.heatmap(data_filtered.drop(['id','host_id'], axis=1).corr(),annot=True,cmap='BuPu',center=0)

